{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Modules\n",
    "\n",
    "We import PyTorch for building neural networks, the MNIST dataset from torchvision, DataLoader for batch processing, and matplotlib/pillow for creating visualizations showing how the model learns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare the MNIST Dataset\n",
    "\n",
    "We download the MNIST dataset and split it into training and test sets. The ToTensor transform converts images to PyTorch tensors and normalizes pixel values to [0, 1]. We use DataLoader to batch the data (32 samples at a time) and shuffle training data for better learning.\n",
    "\n",
    "Here's what the first eight digits of the dataset look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/firsteightimages.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Normalization?\n",
    "\n",
    "Normalization scales input values to a consistent range, helping the neural network learn faster and more reliably. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network Model\n",
    "\n",
    "We create a sequential model that flattens 28x28 images into vectors, then passes them through two hidden layers (128 and 64 neurons) with ReLU activation. Dropout layers (30%) randomly disable neurons during training to prevent overfitting. The final layer outputs 10 values (one per digit 0-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/model_placholder.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Training Components\n",
    "\n",
    "We set up the Adam optimizer to adjust model weights during training and CrossEntropyLoss to measure prediction errors. Adam is efficient for most deep learning tasks and works well with default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training Device\n",
    "\n",
    "We check if a GPU is available and move the model to it for faster training. If no GPU exists, training runs on CPU. GPUs can speed up training by 10-100x for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(f\"Training on: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data for Validation\n",
    "\n",
    "We reserve 10% of training data for validation to monitor overfitting. The validation set helps us see if the model generalizes well to unseen data during training, without touching the final test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Samples for Progress Tracking\n",
    "\n",
    "Before training, we select 15 test images that we'll use to track the model's predictions across epochs. By using the same images throughout training, we can visualize how the model's predictions improve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a fixed set of test samples for tracking progress\n",
    "test_samples = []\n",
    "test_sample_labels = []\n",
    "for images, labels in test_loader:\n",
    "    test_samples.append(images)\n",
    "    test_sample_labels.append(labels)\n",
    "    if len(test_samples) * 32 >= 15:\n",
    "        break\n",
    "\n",
    "test_samples = torch.cat(test_samples)[:15].to(device)\n",
    "test_sample_labels = torch.cat(test_sample_labels)[:15]\n",
    "\n",
    "# Store predictions at specific epochs for GIF\n",
    "epoch_snapshots = []\n",
    "snapshot_epochs = [1, 3, 5, 7, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Training Parameters\n",
    "\n",
    "We set the number of epochs (complete passes through the training data) and create a history dictionary to track training metrics. More epochs allow the model to learn better, but too many can lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase: Forward and Backward Pass\n",
    "\n",
    "For each epoch, we iterate through batches of training data. The forward pass computes predictions, the loss measures error, and backpropagation (loss.backward()) calculates gradients. The optimizer then updates weights to reduce the error. We capture predictions at certain epochs to visualize learning progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = train_loss / len(train_loader)\n",
    "    epoch_acc = train_correct / train_total\n",
    "    epoch_val_loss = val_loss / len(val_loader)\n",
    "    epoch_val_acc = val_correct / val_total\n",
    "    \n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['accuracy'].append(epoch_acc)\n",
    "    history['val_loss'].append(epoch_val_loss)\n",
    "    history['val_accuracy'].append(epoch_val_acc)\n",
    "    \n",
    "    # Save predictions at specific epochs for visualization\n",
    "    if (epoch + 1) in snapshot_epochs:\n",
    "        with torch.no_grad():\n",
    "            snapshot_preds = model(test_samples)\n",
    "            epoch_snapshots.append({\n",
    "                'epoch': epoch + 1,\n",
    "                'predictions': snapshot_preds.cpu(),\n",
    "                'accuracy': epoch_acc\n",
    "            })\n",
    "    \n",
    "    print(f\"{epoch+1}/{epochs} - loss: {epoch_loss:.4f} - accuracy: {epoch_acc:.4f} - val_loss: {epoch_val_loss:.4f} - val_accuracy: {epoch_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can We Test on a Random Image?\n",
    "\n",
    "Pick a random image from the test set and see how the model classifies it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_random_image():\n",
    "    # Pick a random image from test set\n",
    "    idx = np.random.randint(0, len(test_dataset))\n",
    "    image, true_label = test_dataset[idx]\n",
    "    \n",
    "    # Get prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image.unsqueeze(0).to(device)\n",
    "        output = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    \n",
    "    predicted_label = output.argmax(1).item()\n",
    "    confidence = probabilities[predicted_label].item()\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Show the image\n",
    "    ax1.imshow(image.squeeze(), cmap='gray')\n",
    "    ax1.set_title(f\"True Label: {true_label}\\nPredicted: {predicted_label} ({confidence:.1%} confident)\", \n",
    "                  fontsize=14, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Show confidence scores for all digits\n",
    "    digits = list(range(10))\n",
    "    confidences = probabilities.cpu().numpy()\n",
    "    colors = ['green' if i == predicted_label else 'skyblue' for i in digits]\n",
    "    \n",
    "    ax2.barh(digits, confidences, color=colors)\n",
    "    ax2.set_xlabel('Confidence', fontsize=12)\n",
    "    ax2.set_ylabel('Digit', fontsize=12)\n",
    "    ax2.set_title('Prediction Confidence for Each Digit', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlim(0, 1)\n",
    "    ax2.invert_yaxis()\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for i, (digit, conf) in enumerate(zip(digits, confidences)):\n",
    "        ax2.text(conf + 0.01, i, f'{conf:.1%}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return f\"Predicted: {predicted_label}, Actual: {true_label}, Correct: {predicted_label == true_label}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this cell multiple times to test different images. The visualization shows the digit image, the model's prediction, and confidence scores for all 10 possible digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_random_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Save the Trained Model\n",
    "\n",
    "We save the model's learned parameters to a file so it can be loaded later without retraining. This allows us to use the trained model in other applications like a streamlit app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'mnist_model.pth')\n",
    "# print(\"Model saved as 'mnist_model.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
